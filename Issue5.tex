\input{preambule.tex}

\begin{document}

\section{Матричная экспонента, ее свойства и применение к решению нормальных линейных систем}

\subsection{Матричная экспонента}
Необходимо решить ОЛДУ вида:

\begin{equation}
  	\frac{d\vec{x}}{dt} = A\vec{x},\ \vec{x}(t_0) = \vec{x_0},
  	\label{Issue5_1}
\end{equation}

Если $A(t) = ||a_j^i||,\ a_j^i \in \mathbf{R},\ i,j = 1,\dots,\ n$, тогда:

\begin{equation*}
\begin{gathered}
         \vec{x_{0}} = E\vec{x_0},\ \vec{x_1} = E\vec{x_0} + \frac{t-t_0}{1!}A\vec{x_0} = \left(E + \frac{t-t_0}{1!}A\right) \vec{x_0}, \\  
         \vec{x_n} = \left(E + \frac{t-t_0}{1!}A +\ \dots\ + \frac{(t-t_0)^n}{n!}A^n\right)\vec{x_0},	 
\end{gathered}
\end{equation*}

Этот процесс будет сходиться к задаче Коши с решением:

\begin{equation*}
   	\vec{x} = \left(E + \frac{t-t_0}{1!}A +\ \dots\ + \frac{(t-t_0)^n}{n!}A^n+\ \dots \right)\vec{x_0} = \left(\sum\limits_{n = 0}^{\infty} \frac{(t-t_0)^n}{n!}A^n\right)\vec{x_0},	 
\end{equation*}

при условии, что $A^0 = E.$

\begin{definition}
	Матричной экспонентой называют следующий степенной ряд:
	\begin{equation*}
		e^{(t-t_0)A} = E + \frac{t-t_0}{1!}A +\ \dots\ + \frac{(t-t_0)^n}{n!}A^n+\ \dots\ = \sum\limits_{n = 0}^{\infty} \frac{(t-t_0)^n}{n!}A^n.
	\end{equation*}
\end{definition}

\subsection{Свойства матричной экспоненты}

Это квадратная матрица, по размерам аналогична матрице $A$, и каждый элемент этой матрицы представляет из себя степенной ряд с радиусом сходимости $+\infty$.

\begin{enumerate}
		\item Решение задачи Коши для $(\ref{Issue5_1})$, если $A = const$:

		\begin{equation*} 
			\vec{x}(t) = e^{(t-t_0)A}\vec{x_0},\ (\vec{x}(t_0) = \vec{x_0}) .
		\end{equation*}
		
		\item $ e^{0 A} = E.$
		
		\item $e^{(t_1+t_2)A} = e^{t_1A}e^{t_2A} \Rightarrow e^{t_1A}e^{t_2A} = e^{t_2A}e^{t_1A}$ (коммутативность).
		
		\item $\left(e^{tA}\right)^{-1} = e^{-tA}.$
		
		\item $(e^{tA})^{'} = A e^{tA} = e^{tA}A.$

\end{enumerate}

\begin{proof}

Так как квадратные матрицы составляют определенное кольцо, то \\
$A^{n+m} = A^nA^m=A^mA^n.$

\begin{enumerate}

\item

\item $ e^{tA} = E + \frac{t-t_0}{1!}A +\ \dots\ + \frac{(t-t_0)^n}{n!}A^n+\ \dots $, если $t = 0$ :
\[ e^{0A} = E + 0 + \dots = E\]

\item рассматриваем $(\ref{Issue5_1})$, если $\vec{x}(t)$ - решение этого ДУ, то $\vec{x}(t+t_0)$ тоже решение этого ДУ $\forall t_0 \in \mathbf{R}$. ($u = t + t_0$) :

\[ \frac{d\vec{x}(t+t_0)}{dt} = \frac{d\vec{x}}{du}\frac{du}{dt} = \frac{d\vec{x}}{du} = A\vec{x}(u) = A\vec{x}(t+t_0).\]

Тогда $(\ref{Issue5_1})$, с задачей Коши $\vec{x}(0) = \vec{x_0}$ имеет решение:

\[ \vec{x}(t) =  e^{tA}\vec{x_0},\]
\[ \vec{x}(t+t_0) = e^{(t+t_0)}\vec{x_0}\text{ - решение }\frac{d\vec{x}}{dt} = A\vec{x}. \]

Рассмотрим тогда тоже самое уравнение для функции $z(t)$:

\[ \frac{d\vec{z}}{dt} = A\vec{z}, \text{ с задачей Коши } \vec{z}(0) = e^{t_0A}\vec{x_0} \Rightarrow \vec{z}(t) = e^{tA} (e^{t_0A}\vec{x_0}) = (e^{tA}e^{t_0A})\vec{x_0}.\]

Рассмотрим это решение в нуле:

\[ \vec{x}(0 + t_0) = e^{t_0A}\vec{x_0},\]

из основной теоремы следует, что $\vec{x}(t+t_0) = \vec{z}(t)\ \forall t$.

Тогда и получается основная формула:

\[ \vec{x}(t+t_0) = e^{(t+t_0)A}\vec{x_0} = (e^{tA}e^{t_0A})\vec{x_0}\]

\item $E = e^{0A} = e^{(t-t)A} = e^{tA}e^{-tA} = E \Rightarrow \left(e^{tA}\right)^{-1} = e^{-tA}.$

\item Берем представление матричной экспоненты в виде степенного ряда, который можно дифференцировать, тогда получаем:

\[ (e^{tA})^{'} = A + tA^2 +\ \dots\ +\frac{t^{n-1}}{(n-1)!} A^n +\ \dots = A\left(E + tA +\ \dots\ + \frac{t^{n-1}}{(n-1)!}A^{n-1}\right),\]

\[ (e^{tA})^{'} = Ae^{tA} = e^{tA}A.\]

\end{enumerate}

\end{proof}

\textbf{Примечание.} Формула $e^{t(A+B)} = e^{tA}e^{tB}$ не имеет места, кроме случая, если $AB = BA$ (т.е. матрицы коммутативны).

\subsection{Применение к решению нормальных линейных систем}

\begin{theorem}

Пусть $S$ - матрица перехода от исходного базиса к новому базису. Тогда в новой базисе $\overline{A} = S^{-1}AS$, или $A = S\overline{A}S^{-1}$. И главное:

\[e^{tA} = S^{-1}e^{t\overline{A}}S.\]

\end{theorem}

\begin{proof}
	\begin{equation*}
		\begin{gathered}
 e^{tA} = \left(E + tA +\ \dots\ + \frac{t^{n}}{n!}A^{n}\right) = \left(E + tS^{-1}e^{t\overline{A}}S +\ \dots\ + \frac{t^{n}}{n!}(S^{-1}e^{t\overline{A}}S)^{n}\right), \\
 (S\overline{A}S^{-1})^n = S\overline{A}^nS^{-1},\ SES^{-1} = SS^{-1} = E \\
 e^{tA} = S^{-1}e^{t\overline{A}}S.
		\end{gathered}
	\end{equation*}
\end{proof}

Для решения нормальных линейных систем методом матричной экспоненты мы будем находить собственные вектора.

Матрица $A$ в базисе из собственных векторов (если они соответствуют действительным собственным значениям) будет иметь диагональный вид. Произведение диагональной матрицы на диагональную -- диагональная. Тогда для случая без кратных корней:

\[ e^{tA} = E + t\cdot diag(\lambda_1,\ ...\ ,\lambda_n) + \frac{t^n}{n!}\cdot diag(\lambda_1^n,\ ...\ ,\lambda_n^n).\]

\[ e^{tA} = diag(e^{t\lambda_1},\ ...\ , e^{t\lambda_n}).\]

Если $\lambda$ -- корень кратности $l$, то матрица $A$ приводится к Жордановой клетке (диагональная матрица с единицами над главной диагональю).

\[ A = \lambda E + B \Rightarrow B = A - \lambda E. \]

\[ e^{tA} = e^{t(\lambda E + B)} = e^{t\lambda E}e^{tB},\ e^{t\lambda E} = diag(e^{t\lambda},\ ...\ , e^{t\lambda}), e^{tB} = E + tB +\ ...\ + \frac{t^{l-1}}{(l-1)!}B^{l-1} + 0 \]

\begin{equation*}
	\text{тогда } e^{tA} = e^{\lambda t}
 	\begin{pmatrix}
            1\ \ t\ \ \ \ \  \dots\ \ \ \ \ \frac{t^{l-1}}{(l-1)!} \\
            0\ \ 1\ \ t\ \ \ \dots\ \ \ \ \  \frac{t^{l-2}}{(l-2)!} \\
            \dots \\
            0\ \ \ \ \ \ \ \ \ \dots\ \ \ \ \ \ \ \ \  1
    \end{pmatrix}
\end{equation*}

\textbf{Метод решения линейных неоднородных уравнений с постоянными коэффициентами} (матричный метод вариации постоянной)

\[ \frac{d\vec{x}}{dt} = A\vec{x} + \vec{f}(t),\ \ \text{ решение будем искать в виде } \ \vec{x}(t) = e^{tA}\vec{C}(t), \]

\[ \text{ тогда } Ae^{tA}\vec{C}(t) + e^{tA}\dot{\vec{C}}(t) = Ae^{tA}\vec{C} + \vec{f}(t),\]

\[ e^{tA}\dot{\vec{C}}(t) = \vec{f}(t)\ \Rightarrow \dot{\vec{C}}(t) = (e^{tA})^{-1}\vec{f}(t) = e^{-tA}\vec{f}(t). \]

\newpage

\section{Теоремы существования и единственности решения задачи Коши для нормальной линейной системы уравнений и
для линейного уравнения $n$-го порядка в нормальном виде}

$\textbf{Постановка задачи}$

Задача Коши для нормальной системы ОДУ

\begin{equation}
 \dot{\vec{x}} = \vec{f}(t, \vec{x})
 \label{Issue5_2}
\end{equation}

состоит в отыскании решения $\vec{x} = \vec{x}(t)$ , удовлетворяющего начальным условиям

\[ \vec{x}(t_0) = \vec{x_0} .\]


Предположим, что выполнены следующие условия.

$\textbf{(У1)}$ Пусть $\vec{f}(t, \vec{x}) \in C(G)$, т.е. существует постоянная $M=\max _{G}|\vec{f}(t, \vec{x})|$, следовательно $|\vec{f}(t, \vec{x})| \leq M$ -- равномерно ограничена в $G$.

$\textbf{(У2)}$ Пусть $\vec{f}(t, \vec{x})$ в любой замкнутой ограниченной подобласти $\bar{g} \subset G$ удовлетворяет условию Липиица по переменой $\vec{x}$, т.е. существует постоянная Липиица $N>0$ (не зависящая ни от $\vec{x}$, ни от $\vec{y}$ ) такая, что для всех $(t, \vec{x}),(t, \vec{y}) \in \bar{g}$ выполняется неравенство

$$
|\vec{f}(t, \vec{x})-\vec{f}(t, \vec{y})| \leq N|\vec{x}-\vec{y}| .
$$

$\textbf{Замечание.}$ Это условие будет выполнено, в частности, если существуют частные производные $\frac{\partial f^{i}(x, y)}{\partial x^{j}} \in C(G) .$

\end{document}
 
